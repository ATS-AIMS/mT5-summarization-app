{"Article About The Outfits In Squid Game (Korean)": "오징어 게임은 456명의 참가자가 456억원의 상금이 걸린 서바이벌 게임에서 최후의 승자가 되기 위해 목숨을 걸고 도전하는 이야기다\n\n넷플릭스 오리지널 '오징어 게임' 속 초록색 체육복 의상을 두고 한-중 네티즌 간의 설전이 이어지고 있다.\n\n지난 5일 중국 매체 관찰자망 등은 \"한국에서 '오징어 게임' 속 의상을 중국이 베꼈다고 주장하고 있다\"는 소식을 전하며 반박에 나섰다.\n\n특히 전날 서경덕 성신여대 교수가 자신의 인스타그램에 올린 글을 문제 삼았다.\n\n관찰자망은 \"서 교수가 그동안 이런 의제를 놓고 여러 번 중국을 자극했다\"라며 \"이번에는 목표를 잘못 골랐다\"라고 비난했다.\n\n앞서 서 교수는 중국 내 다양한 저작권 침해 사례를 언급하며 중국 쇼핑몰에서 '오징어 게임' 속 이정재의 초록색 운동복에 '중국'이라는 한자가 적힌 채 판매되고 있다고 주장한 바 있다.", "Players Defrauded NBA Health Plan (English)": "Eighteen former NBA players have been indicted on charges that they allegedly defrauded a health care plan of millions of dollars that served current and former players, according to an indictment unsealed Thursday.\n\nManhattan federal prosecutors allege in the indictment that the 18 former NBA players and one of their family members took part in a \"widespread scheme to defraud\" the NBA's health plan by submitting nearly $4 million in \"false and fraudulent\" claims to be reimbursed for medical and dental services that had not actually been given.\nThe people charged in the indictment received about $2.5 million in fraudulent proceeds, prosecutors said in the indictment.\nUS Attorney for the Southern District of New York Audrey Strauss said at a press conference Thursday the FBI arrested 16 of the defendants, including Terrence Williams, who she called the \"leader of the conspiracy.\"\nCNN has reached out to Williams for comment.\nStrauss said Williams allegedly obtained fraudulent medical and dental invoices, sent those invoices to his co-conspirators, who then submitted the claims to the plan, which paid \"most\" of their claims for procedures that they never received.\nThe alleged scheme, Strauss said, began around November 2017.\nIn all, 19 people were indicted on one count of conspiracy to commit health care fraud and wire fraud.\nEach person allegedly tried to claim between $65,000 to as much as $420,000 in fraudulent medical service reimbursements, Strauss said. She said that in many cases the people submitting the invoices were nowhere near the location where they claimed to be receiving treatments.\n\"Travel records, email, GPS data and other evidence shows that the defendants who purportedly received medical and dental services at a location on a particular date were often nowhere near the providers offices when the claimed services were supposedly provided,\" Strauss said.\nOne former NBA player, Strauss said, submitted a bill for $48,000 claiming he had IV sedation and root canals and crowns on eight teeth on December 20, 2018 at an office in Beverly Hills, California. But Strauss said, on that date, travel records and even \"publicly available box scores\" show the man was actually playing professional basketball in Taiwan.\nThe indictment alleges that at least 10 co-defendants agreed to pay Williams about $230,000 total in \"kickbacks\" in exchange for him providing them with fake invoices to help with their scheme.\nCNN has reached out to the NBA and the NBA players union for comment. CNN is also to reaching out to the defendants.", "Gorilla Famous For Selfie With Caretaker Passes Away (Arabic)": "الغوريلا نداكسي صاحبة صورة \"السيلفي\" الشهيرة تنفق بين ذراعي منقذها\nالغوريلا الجبلية نداكسي، التي اشتهرت على مواقع التواصل الاجتماعي بعد نشر صورة \"سيلفي\" لها مع غوريلا أخرى وأحد حراس الأدغال، نفقت اليوم بعد صراع طويل مع المرض عن عمر 14 عاماً.\n\nونفقت الغوريلا بين ذراعي أندريه بوما، الحارس الذي أنقذها عندما كانت رضيعة، في دار لأيتام الغوريلا في فيرونجا في جمهورية الكونغو الديمقراطية.", "Gorilla Famous For Selfie With Caretaker Passes Away (English)": "A mountain gorilla whose picture went viral after she photobombed a park ranger's selfie has died at 14.\n\nNdakazi \"took her final breath in the loving arms of her caretaker and lifelong friend, Andre Bauma,\" a statement from the Virunga National Park in the Democratic Republic of Congo said Tuesday.", "[OOD] CKS1B promotes the progression of hepatocellular carcinoma (English)": "CKS1B promotes the progression of hepatocellular carcinoma by activating JAK/STAT3 signal pathway. Hepatocellular carcinoma (HCC) is a malignancy of considerable concern due to its continuous increase in morbidity and mortality. This study attempts to identify the molecules that play a key role in the progression of HCC, explore its potential mechanism, and provide more target choices for targeted therapy. Using overexpression plasmid and shRNA, CKS1B was respectively overexpressed and knocked down to explore its biological function roles in HCC progression and development. MTT and colony formation assays showed that knockdown of CKS1B inhibited the survival and proliferation of HCC cell lines (Hep3B and Huh7). The flow cytometry and western blot analysis showed that knockdown of CKS1B significantly induced the apoptosis of Hep3B and Huh7 cells. The wound healing and transwell invasion assays showed that knockdown of CKS1B had a significant inhibitory effect on the migration and invasion of Hep3B and Huh7 cells. These functional tests confirmed that CKS1B acts as an oncogene that regulates the malignant progression of HCC. Moreover, this study also demonstrated that knockdown of CKS1B inhibited the activation of JAK/STAT3 pathway, evidenced by the significantly downregulated p-STAT3 protein expression. Furthermore, knockdown of CKS1B also downregulated STAT3 target genes TIMP-1, Bcl-2 and VEGF, which were involved in controlling cell apoptosis and migration. On the contrary, overexpression of CKS1B caused the completely opposite results. Taken together, CKS1B acts as an oncogene to promote the proliferation and metastasis of HCC cells by activating JAK/STAT3 signaling pathway.", "[OOD] Transformer Model Architecture (English)": "Most competitive neural sequence transduction models have an encoder-decoder structure [5, 2, 35]. Here, the encoder maps an input sequence of symbol representations (x1, ..., xn) to a sequence of continuous representations z = (z1, ..., zn). Given z, the decoder then generates an output sequence (y1, ..., ym) of symbols one element at a time. At each step the model is auto-regressive [10], consuming the previously generated symbols as additional input when generating the next. \nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully connected layers for both the encoder and decoder, shown in the left and right halves of Figure 1, respectively. \n\nEncoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has two\nsub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, positionwise fully connected feed-forward network. We employ a residual connection [11] around each of\nthe two sub-layers, followed by layer normalization [1]. That is, the output of each sub-layer is\nLayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer\nitself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\nlayers, produce outputs of dimension dmodel = 512.\n\nDecoder: The decoder is also composed of a stack of N = 6 identical layers. In addition to the two\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\nattention over the output of the encoder stack. Similar to the encoder, we employ residual connections\naround each of the sub-layers, followed by layer normalization. We also modify the self-attention\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This\nmasking, combined with fact that the output embeddings are offset by one position, ensures that the\npredictions for position i can depend only on the known outputs at positions less than i.\n"}